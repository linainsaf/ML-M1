{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "neural networks and deep learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMkgv/1sEEqQ03I2/PuvYL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linainsaf/ML-M1/blob/main/neural_networks_and_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IKxNTe9ZWc1"
      },
      "source": [
        "import pickle\n",
        "import gzip\n",
        "import torch \n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qke6qwA-MTTr"
      },
      "source": [
        "PATH = ''\n",
        "FILENAME = 'mnist1.pkl.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDUzAQ6VQ-hD"
      },
      "source": [
        "def get_files(path,filename):\n",
        "    with gzip.open((PATH + FILENAME), \"rb\") as file:\n",
        "        ((x_train, y_train), (x_val, y_val), _) = pickle.load(file, encoding='latin-1')\n",
        "    return x_train, y_train, x_val, y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdglrzK6Bzlj"
      },
      "source": [
        "def tensor_map(x_train,y_train,x_val,y_val): return map(torch.tensor,(x_train,y_train,x_val,y_val))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFj_BM6QIyg1"
      },
      "source": [
        "def preprocess(x):\n",
        "    return x.view(-1, 1, 28, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSbrcL3kIyeH"
      },
      "source": [
        "def conv(in_size, out_size, pad=1): \n",
        "    return nn.Conv2d(in_size, out_size, kernel_size=3, stride=2, padding=pad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2tquedjIybC"
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_size:int, hidden_size:int, out_size:int, pad:int):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv(in_size, hidden_size, pad)\n",
        "        self.conv2 = conv(hidden_size, out_size, pad)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(hidden_size)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(out_size)\n",
        "    \n",
        "    def convblock(self, x):\n",
        "        x = F.relu(self.batchnorm1(self.conv1(x)))\n",
        "        x = F.relu(self.batchnorm2(self.conv2(x)))\n",
        "        return x\n",
        "    \n",
        "    def forward(self, x): return x + self.convblock(x) # skip connection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWxmtxw6IyYd"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_classes=10):\n",
        "        super().__init__()\n",
        "        self.res1 = ResBlock(1, 8, 16, 15)\n",
        "        self.res2 = ResBlock(16, 32, 16, 15)\n",
        "        self.conv = conv(16, n_classes)\n",
        "        self.batchnorm = nn.BatchNorm2d(n_classes)\n",
        "        self.maxpool = nn.AdaptiveMaxPool2d(1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = preprocess(x)\n",
        "        x = self.res1(x)\n",
        "        x = self.res2(x) \n",
        "        x = self.maxpool(self.batchnorm(self.conv(x)))\n",
        "        return x.view(x.size(0), -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbLcBQcuIyVa"
      },
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None, scheduler=None):\n",
        "    loss = loss_func(model(xb), yb)\n",
        "    acc = accuracy(model(xb), yb)\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    return acc, loss.item(), len(xb)\n",
        "\n",
        "def accuracy(out, yb):\n",
        "    # in PyTorch one cannot take the mean of ints \n",
        "    # thus, values have to be converted into floats first\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yStwGpAYIyTF"
      },
      "source": [
        "def get_model():\n",
        "    model = ResNet()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    return model, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnrqm9-OIyPC"
      },
      "source": [
        "def get_data_batches(x_train, y_train, x_val, y_val, bs):\n",
        "    train_ds = TensorDataset(x_train, y_train)\n",
        "    val_ds = TensorDataset(x_val, y_val)\n",
        "    # DataLoader = generator\n",
        "    return (\n",
        "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
        "        DataLoader(val_ds, batch_size=bs * 2),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_HRji-QIyMg"
      },
      "source": [
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl, scheduler=None):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        # iterate over data loader object (generator)\n",
        "        for xb, yb in train_dl:\n",
        "            loss_batch(model, loss_func, xb, yb, opt, scheduler)\n",
        "\n",
        "        model.eval()\n",
        "        # no gradient computation for evaluation mode\n",
        "        with torch.no_grad():\n",
        "            accs, losses, nums = zip(\n",
        "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "            )\n",
        "        \n",
        "        #NOTE: important to multiply with batch size and sum over values \n",
        "        #      to account for varying batch sizes\n",
        "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "        val_acc = np.sum(np.multiply(accs, nums)) / np.sum(nums)\n",
        "\n",
        "        print(\"Epoch:\", epoch+1)\n",
        "        print(\"Loss: \", val_loss)\n",
        "        print(\"Accuracy: \", val_acc)\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPVmxaXVIyJa"
      },
      "source": [
        "bs=64 #128\n",
        "lr=0.01\n",
        "n_epochs = 5\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "\n",
        "# get data set\n",
        "x_train, y_train, x_val, y_val = get_files(PATH, FILENAME)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOsIOmX4IyFt"
      },
      "source": [
        "# map tensor function to all inputs (X) and targets (Y) to create tensor data sets\n",
        "x_train, y_train, x_val, y_val = tensor_map(x_train, y_train, x_val, y_val)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FWzdCs0Ix_a"
      },
      "source": [
        "# get math.ceil(x_train.shape[0]/batch size) train and val mini batches of size bs\n",
        "train_dl, val_dl = get_data_batches(x_train, y_train, x_val, y_val, bs)\n",
        "\n",
        "# get model and optimizer\n",
        "model, opt = get_model()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nbLl0lQIxx0",
        "outputId": "78447483-0742-4853-e523-17598cb3e4f3"
      },
      "source": [
        "# train\n",
        "fit(n_epochs, model, loss_func, opt, train_dl, val_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Loss:  0.16388425068855286\n",
            "Accuracy:  0.9527\n",
            "\n",
            "Epoch: 2\n",
            "Loss:  0.11397531992793083\n",
            "Accuracy:  0.9685\n",
            "\n",
            "Epoch: 3\n",
            "Loss:  0.12378384310156107\n",
            "Accuracy:  0.9664\n",
            "\n",
            "Epoch: 4\n",
            "Loss:  0.09394516428336501\n",
            "Accuracy:  0.9736\n",
            "\n",
            "Epoch: 5\n",
            "Loss:  0.09159027404040099\n",
            "Accuracy:  0.9726\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dL_yeqaJp4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
